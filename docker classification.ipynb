{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision.models as models \n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from tqdm.auto import tqdm\n",
    "import torchmetrics\n",
    "import cv2\n",
    "from glob import glob\n",
    "import requests\n",
    "from io import StringIO\n",
    "from urllib.parse import urlparse\n",
    "from tsai.all import *\n",
    "os.environ[\"cuda_visible_devices\"] = '0'\n",
    "device0 = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://storage.googleapis.com/download/storage/v1/b/vitalring-seoul.appspot.com/o/ppgContinuous%2FsyFotyWOdfPVPfa8ZOkhJBodgpJ3%2FsyFotyWOdfPVPfa8ZOkhJBodgpJ3_1706757218000.csv?generation=1706757229270812&alt=media\"\n",
    "destination_path = \"downloaded_file.csv\"\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AF       PPG\n",
      "0   0  0.478063\n",
      "1   0  0.458766\n",
      "2   0  0.435854\n",
      "3   0  0.419918\n",
      "4   0  0.401380\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    # Assuming the CSV content is UTF-8 encoded\n",
    "    csv_data = response.content.decode('utf-8')\n",
    "    parsed_url = urlparse(url)\n",
    "    filename = parsed_url.path.split('/')[-1]\n",
    "    # Use pandas to read the CSV data into a DataFrame\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    df.rename(columns={'PPG': 'AF', 'Type_1': 'PPG'}, inplace=True)\n",
    "    # Now 'df' is a pandas DataFrame containing the CSV data\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,data ,transform=None, target_transform=None):\n",
    "        self.PPG_data=data\n",
    "    def __len__(self):\n",
    "        return len(self.PPG_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        signal_tensor=self.PPG_data[idx]\n",
    "        \n",
    "        return signal_tensor\n",
    "\n",
    "\n",
    "test_data=torch.empty(len(df)//2500+1,1,3000)\n",
    "for i in range(len(df)//2500):\n",
    "    if len(df)//2500-1==i:\n",
    "        signal_csv=df.loc[i*2500-499:(i+1)*2500]['PPG']\n",
    "        test_data[i]=torch.tensor(signal_csv.to_numpy())\n",
    "        signal_csv=df.loc[len(df)-3000:]['PPG']\n",
    "        test_data[i+1]=torch.tensor(signal_csv.to_numpy())\n",
    "    else:\n",
    "        signal_csv=df.loc[i*2500:(i+1)*2500+499]['PPG']\n",
    "        test_data[i]=torch.tensor(signal_csv.to_numpy())\n",
    "        \n",
    "test_dataset=CustomDataset(test_data)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1148.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5435649402206764e-05,\n",
       " 0.008535649627447128,\n",
       " 0.0025514778681099415,\n",
       " 0.0053351446986198425,\n",
       " 0.006695276126265526]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(model,dataloader):\n",
    "    validation_tqdm=tqdm(dataloader)\n",
    "    model.eval()\n",
    "    val_count=0\n",
    "    predict_list=[]\n",
    "    with torch.no_grad():\n",
    "        for x in validation_tqdm:\n",
    "            val_count+=1\n",
    "            x=x.to(device0).float()\n",
    "            predict = model(x).to(device0)\n",
    "            predict_list.append(F.sigmoid(predict).item())\n",
    "    return predict_list\n",
    "\n",
    "model =GRU_FCN(1,1,3000).to(device0)\n",
    "model.load_state_dict(torch.load('../../model/architecture_waveform/PPG_GRU_FCN_callback.pt'), strict=False)\n",
    "predict_list=test(model,test_dataloader)\n",
    "predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ppgContinuous_syFotyWOdfPVPfa8ZOkhJBodgpJ3_syFotyWOdfPVPfa8ZOkhJBodgpJ3_1706756902000.csv'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(predict_list).round(3)\n",
    "str11='./data/ppgContinuous_syFotyWOdfPVPfa8ZOkhJBodgpJ3_syFotyWOdfPVPfa8ZOkhJBodgpJ3_1706756902000.csv'\n",
    "filename = str11.split('/')[-1]\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def modify_csv(input_file, output_file):\n",
    "    # CSV 파일 읽기\n",
    "    with open(input_file, 'r', newline='') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        data = list(reader)\n",
    "\n",
    "    # 데이터 수정 (예: 첫 번째 행의 첫 번째 열 값을 변경)\n",
    "    data[0][0] = 'New Value'\n",
    "\n",
    "    # 수정된 데이터를 CSV 파일에 쓰기\n",
    "    with open(output_file, 'w', newline='') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerows(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
