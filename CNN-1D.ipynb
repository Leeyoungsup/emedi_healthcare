{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision.models as models \n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from glob import glob\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import torch.functional as F\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm_notebook\n",
    "device0 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_glob, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_list = glob(img_glob)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.file_name_list=[]\n",
    "        self.file_remove_list=[]\n",
    "        self.label_list=[]\n",
    "        \n",
    "        for i in range(len(self.img_list)):\n",
    "            self.file_name_list.append(os.path.splitext(os.path.basename(self.img_list[i]))[0][:9])\n",
    "\n",
    "        for i in range(len(self.file_name_list)):\n",
    "            label_index=self.img_labels.loc[self.img_labels['PathologyNumber'] == self.file_name_list[i]]\n",
    "            if len(label_index)==0:\n",
    "                self.file_remove_list.append(self.img_list[i])\n",
    "            else:\n",
    "                if label_index['MMR status'].to_list()[0]=='Normal':\n",
    "                    self.label_list.append(0)\n",
    "                else:\n",
    "                    self.label_list.append(1)\n",
    "        for i in range(len(self.file_remove_list)):\n",
    "            self.img_list.remove(self.file_remove_list[i])\n",
    "        self.image_x5=[f.replace('/2.5x_standard', '/5x_standard') for f in self.img_list]\n",
    "        self.image_x10=[f.replace('/2.5x_standard', '/10x_standard') for f in self.img_list]\n",
    "        img_5x_temp=[]\n",
    "        img_10x_temp=[]\n",
    "        for i in range(len(self.img_list)):\n",
    "            for j in range(4):\n",
    "                img_5x_temp.append(self.image_x5[i][:-4]+'_'+str(j)+'.jpg')\n",
    "            for j in range(16):\n",
    "                img_10x_temp.append(self.image_x10[i][:-4]+'_'+str(j)+'.jpg')\n",
    "            self.image_x5[i]=img_5x_temp\n",
    "            self.image_x10[i]=img_10x_temp\n",
    "        self.transform = T.Resize(224)\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = (1-self.transform(read_image(self.img_list[idx])))/255\n",
    "        label = self.label_list[idx]\n",
    "        image_5x=torch.zeros(4,3,224,224)\n",
    "        image_10x=torch.zeros(16,3,224,224)\n",
    "        for i in range(4):\n",
    "            image_5x[i]=self.transform(read_image(self.image_x5[idx][i]))\n",
    "        for i in range(16):\n",
    "            image_10x[i]=self.transform(read_image(self.image_x10[idx][i]))\n",
    "        image_5x=np.transpose(1-image_5x, axes=(1, 0, 2,3))/255\n",
    "        image_10x=np.transpose(1-image_10x, axes=(1, 0, 2,3))/255\n",
    "        image_5x=torch.reshape(1-image_5x,(3*4,224,224))\n",
    "        image_10x=torch.reshape(1-image_10x,(16*3,224,224))\n",
    "        \n",
    "        return image,image_5x,image_10x,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_glob='../../data/CycleGANData/3divisionTile/2.5x_standard/*.jpg'\n",
    "annotations_file='../../data/OriginalData/MMR.csv'\n",
    "dataset=CustomImageDataset(annotations_file,img_glob)\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "validation_size = int(dataset_size * 0.1)\n",
    "test_size = dataset_size - train_size - validation_size\n",
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1D_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1D_1,self).__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "        torch.nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "        torch.nn.MaxPool1d(kernel_size=2,stride=2),\n",
    "        torch.nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "        torch.nn.MaxPool1d(kernel_size=2,stride=2) \n",
    "        ,\n",
    "        torch.nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3),\n",
    "        torch.nn.MaxPool1d(kernel_size=2,stride=2) \n",
    "        ,nn.LSTM(input_size=123, hidden_size=64,bidirectional=True)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x=self.layer1(x)\n",
    "        return x\n",
    "\n",
    "class CNN1D_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1D_2,self).__init__()\n",
    "        self.conv1d=torch.nn.Sequential(torch.nn.Conv1d(in_channels=128, out_channels=64, kernel_size=3),\n",
    "                                        torch.nn.MaxPool1d(kernel_size=2,stride=2),\n",
    "                                        nn.Flatten(start_dim=1,end_dim=-1),\n",
    "                                        nn.LSTM(input_size=4032, hidden_size=64),\n",
    "                                        nn.Linear(in_features = 64, out_features = 256),\n",
    "                                        nn.LeakyReLU(),\n",
    "                                        nn.Dropout1d(0.5),\n",
    "                                        nn.Linear(in_features = 256, out_features = 128),\n",
    "                                        nn.LeakyReLU(),\n",
    "                                        nn.Dropout1d(0.5),\n",
    "                                        nn.Linear(in_features = 256, out_features = 1))\n",
    "    def forward(self,x):\n",
    "        x=self.conv1d(x)\n",
    "        return x\n",
    "    \n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1D,self).__init__()\n",
    "        self.cnn1d_1=CNN1D_1().to(device0)\n",
    "        self.cnn1d_2=CNN1D_2().to(device0)\n",
    "    def forward(self,x):\n",
    "        x=self.cnn1d_1(x)\n",
    "        x=self.cnn1d_2(x)\n",
    "        return x\n",
    "    \n",
    "model = CNN1D().to(device0)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [CNN1D_1: 1, Sequential: 2, Conv1d: 3, MaxPool1d: 3, Conv1d: 3, MaxPool1d: 3, Conv1d: 3, MaxPool1d: 3, LSTM: 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torchinfo/torchinfo.py:295\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m--> 295\u001b[0m     _ \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49mx, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    296\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[0;32mIn[232], line 43\u001b[0m, in \u001b[0;36mCNN1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcnn1d_1(x)\n\u001b[0;32m---> 43\u001b[0m x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn1d_2(x)\n\u001b[1;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[0;32mIn[232], line 33\u001b[0m, in \u001b[0;36mCNN1D_2.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[0;32m---> 33\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1d(x)\n\u001b[1;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mTypeError\u001b[0m: conv1d() received an invalid combination of arguments - got (tuple, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!tuple of (Tensor, tuple)!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!tuple of (Tensor, tuple)!, !Parameter!, !Parameter!, !tuple of (int,)!, !tuple of (int,)!, !tuple of (int,)!, int)\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[235], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m summary(model,(\u001b[39m32\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1000\u001b[39;49m))\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torchinfo/torchinfo.py:223\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m validate_user_params(\n\u001b[1;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    220\u001b[0m x, correct_input_size \u001b[39m=\u001b[39m process_input(\n\u001b[1;32m    221\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[1;32m    222\u001b[0m )\n\u001b[0;32m--> 223\u001b[0m summary_list \u001b[39m=\u001b[39m forward_pass(\n\u001b[1;32m    224\u001b[0m     model, x, batch_dim, cache_forward_pass, device, model_mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    225\u001b[0m )\n\u001b[1;32m    226\u001b[0m formatting \u001b[39m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[1;32m    227\u001b[0m results \u001b[39m=\u001b[39m ModelStatistics(\n\u001b[1;32m    228\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[1;32m    229\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torchinfo/torchinfo.py:304\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    303\u001b[0m     executed_layers \u001b[39m=\u001b[39m [layer \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m summary_list \u001b[39mif\u001b[39;00m layer\u001b[39m.\u001b[39mexecuted]\n\u001b[0;32m--> 304\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecuted layers up to: \u001b[39m\u001b[39m{\u001b[39;00mexecuted_layers\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     \u001b[39mif\u001b[39;00m hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [CNN1D_1: 1, Sequential: 2, Conv1d: 3, MaxPool1d: 3, Conv1d: 3, MaxPool1d: 3, Conv1d: 3, MaxPool1d: 3, LSTM: 3]"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
