{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision.models as models \n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from glob import glob\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, RocCurveDisplay\n",
    "from tqdm.auto import tqdm\n",
    "import torchmetrics\n",
    "import cv2\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "device0 = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786cd196be1d43b2b90dd2fa66ebe540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1030 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataload\n",
    "\n",
    "def standardize(signal):\n",
    "    mean_val = sum(signal) / len(signal)\n",
    "    std_dev = (sum((x - mean_val) ** 2 for x in signal) / len(signal)) ** 0.5\n",
    "    standardized_signal = [(x - mean_val) / std_dev for x in signal]\n",
    "    return standardized_signal\n",
    "def min_max_normalize(signal):\n",
    "    min_val = min(signal)\n",
    "    max_val = max(signal)\n",
    "    normalized_signal = [(x - min_val) / (max_val - min_val) for x in signal]\n",
    "    return normalized_signal\n",
    "def resized(data,N):\n",
    "    M=data.size\n",
    "    res=np.empty(N,data.dtype)\n",
    "    carry=0\n",
    "    m=0\n",
    "    for n in range(N):\n",
    "        sum = carry\n",
    "        while m*N - n*M < M :\n",
    "            sum += data[m]\n",
    "            m += 1\n",
    "        carry = (m-(n+1)*M/N)*data[m-1]\n",
    "        sum -= carry\n",
    "        res[n] = sum*N/M\n",
    "    return res\n",
    "def vector_magnitude_normalize(signal):\n",
    "    signal_array = np.array(signal)\n",
    "    magnitude = np.linalg.norm(signal_array)\n",
    "    normalized_signal = signal_array / magnitude\n",
    "    return normalized_signal\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data,label ,transform=None, target_transform=None):\n",
    "        self.PPG_data=data\n",
    "        self.PPG_label=label\n",
    "    def __len__(self):\n",
    "        return len(self.PPG_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signal_tensor=self.PPG_data[idx]\n",
    "        AF_signal_label=self.PPG_label[idx]\n",
    "        return signal_tensor,AF_signal_label\n",
    "\n",
    "\n",
    "test_data_list=glob('../../data/nor_collection/**/*.csv')\n",
    "\n",
    "test_data=torch.empty(len(test_data_list),1,750)\n",
    "test_label=torch.empty(len(test_data_list),1)\n",
    "\n",
    "    \n",
    "for i in tqdm(range(len(test_data_list))):\n",
    "    signal_csv=pd.read_csv(test_data_list[i])['PPG'].to_numpy()\n",
    "    AF_signal_label=0\n",
    "\n",
    "    signal_csv=np.array(min_max_normalize(signal_csv))\n",
    "    test_data[i]=torch.tensor(resized(signal_csv,750))\n",
    "    test_label[i]=torch.tensor([AF_signal_label])\n",
    "\n",
    "test_dataset=CustomDataset(test_data ,test_label)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1D,self).__init__()\n",
    "        self.conv1=nn.Conv1d(in_channels=1, out_channels=50, kernel_size=3,padding='same', padding_mode='replicate')\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout=nn.Dropout1d(0.5)\n",
    "        self.pool1=torch.nn.MaxPool1d(kernel_size=5)\n",
    "        self.conv2=nn.Conv1d(in_channels=50, out_channels=50, kernel_size=3,padding='same', padding_mode='replicate')\n",
    "        self.relu2=nn.ReLU()\n",
    "        self.dropout2=nn.Dropout1d(0.5)\n",
    "        self.pool2=torch.nn.MaxPool1d(kernel_size=5)\n",
    "        self.fc1=nn.Linear(1500, 200, bias=False)\n",
    "        self.fc2=nn.Linear(200, 1, bias=False)\n",
    "    def forward(self,x):\n",
    "        \n",
    "        x=self.conv1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.dropout(x)\n",
    "        x=self.pool1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.relu2(x)\n",
    "        x=self.dropout2(x)\n",
    "        x=self.pool2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x=self.fc1(x)\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    \n",
    "accuracy = torchmetrics.Accuracy(task=\"binary\", num_classes=1).to(device0)\n",
    "model = CNN1D().to(device0)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.load_state_dict(torch.load('../../model/Waveform/Type_normalization/CNN_1D.pt'))\n",
    "m = nn.Sigmoid()\n",
    "y_total=torch.empty((0,1))\n",
    "predict_total=torch.empty((0,1))\n",
    "with torch.no_grad():\n",
    "    for x, y in test_dataloader:\n",
    "        y = y.to(device0).float()\n",
    "        x=x.to(device0).float()\n",
    "        y_total=torch.cat([y_total,y.cpu()])\n",
    "        predict = model(x).to(device0)\n",
    "        predict_total=torch.cat([predict_total,m(predict).cpu()])\n",
    "        acc=accuracy(predict, y)\n",
    "        cost = criterion(predict, y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prdiction_accuracy=37.4757281553398\n"
     ]
    }
   ],
   "source": [
    "a=np.array(torch.where(predict_total<0.5,1,0)).mean()\n",
    "print(f'prdiction_accuracy={a*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5339],\n",
       "        [0.7477],\n",
       "        [0.8677],\n",
       "        ...,\n",
       "        [0.4020],\n",
       "        [0.6193],\n",
       "        [0.5132]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
