{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision.models as models \n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from glob import glob\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import torch.functional as F\n",
    "import torchvision.transforms as T\n",
    "from tqdm.notebook import tqdm\n",
    "import torchmetrics\n",
    "import sklearn\n",
    "import cv2\n",
    "device0 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "Type_class='Type_normalization'\n",
    "batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resized(data,N):\n",
    "    M=data.size\n",
    "    res=np.empty(N,data.dtype)\n",
    "    carry=0\n",
    "    m=0\n",
    "    for n in range(N):\n",
    "        sum = carry\n",
    "        while m*N - n*M < M :\n",
    "            sum += data[m]\n",
    "            m += 1\n",
    "        carry = (m-(n+1)*M/N)*data[m-1]\n",
    "        sum -= carry\n",
    "        res[n] = sum*N/M\n",
    "    return res\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data,label ,transform=None, target_transform=None):\n",
    "        self.PPG_data=data\n",
    "        self.PPG_label=label\n",
    "    def __len__(self):\n",
    "        return len(self.PPG_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signal_tensor=self.PPG_data[idx]\n",
    "        AF_signal_label=self.PPG_label[idx]\n",
    "        return signal_tensor,AF_signal_label\n",
    "    \n",
    "test_csv_path ='../../data/AF/Waveform_30/test/'\n",
    "test_data_list=glob(test_csv_path+Type_class+'/**/*.csv')\n",
    "test_data=torch.empty(len(test_data_list),1,750)\n",
    "test_label=torch.empty(len(test_data_list),1)\n",
    "for i in tqdm(range(len(test_data_list))):\n",
    "    signal_csv=pd.read_csv(test_data_list[i])['PPG'].to_numpy()\n",
    "    test_data_list[i].find('positive')\n",
    "    AF_signal_label=0\n",
    "    if test_data_list[i].find('positive')!=-1:\n",
    "        AF_signal_label=1\n",
    "    else:\n",
    "        AF_signal_label=0\n",
    "    \n",
    "    test_data[i]=torch.tensor(resized(signal_csv,750))\n",
    "    test_label[i]=torch.tensor([AF_signal_label])\n",
    "test_dataset=CustomDataset(test_data ,test_label)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import flatten\n",
    "\n",
    "\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1D,self).__init__()\n",
    "        self.conv1=nn.Conv1d(in_channels=1, out_channels=50, kernel_size=3,padding='same', padding_mode='replicate')\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout=nn.Dropout1d(0.5)\n",
    "        self.pool1=torch.nn.MaxPool1d(kernel_size=5)\n",
    "        self.conv2=nn.Conv1d(in_channels=50, out_channels=50, kernel_size=3,padding='same', padding_mode='replicate')\n",
    "        self.relu2=nn.ReLU()\n",
    "        self.dropout2=nn.Dropout1d(0.5)\n",
    "        self.pool2=torch.nn.MaxPool1d(kernel_size=5)\n",
    "        self.fc1=nn.Linear(1500, 200, bias=False)\n",
    "        self.fc2=nn.Linear(200, 1, bias=False)\n",
    "    def forward(self,x):\n",
    "        \n",
    "        x=self.conv1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.dropout(x)\n",
    "        x=self.pool1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.relu2(x)\n",
    "        x=self.dropout2(x)\n",
    "        x=self.pool2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x=self.fc1(x)\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    \n",
    "accuracy = torchmetrics.Accuracy(task=\"binary\", num_classes=1).to(device0)\n",
    "model = CNN1D().to(device0)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "summary(model,(batch_size,1,750))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.load_state_dict(torch.load('../../model/Waveform/Type_normalization/CNN_1D.pt'))\n",
    "m = nn.Sigmoid()\n",
    "y_30_25Hz=torch.empty((0,1))\n",
    "predict_30_25Hz=torch.empty((0,1))\n",
    "with torch.no_grad():\n",
    "    for x, y in test_dataloader:\n",
    "        y = y.to(device0).float()\n",
    "        x=x.to(device0).float()\n",
    "        y_30_25Hz=torch.cat([y_30_25Hz,y.cpu()])\n",
    "        predict = model(x).to(device0)\n",
    "        predict_30_25Hz=torch.cat([predict_30_25Hz,m(predict).cpu()])\n",
    "        acc=accuracy(predict, y)\n",
    "        cost = criterion(predict, y)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, RocCurveDisplay\n",
    "\n",
    "fpr4, tpr4, cut4 = roc_curve(y_30_25Hz,predict_30_25Hz)\n",
    "y_30_25Hz_score=roc_auc_score(y_30_25Hz,predict_30_25Hz)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "fig.set_facecolor('white')\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(fpr4, tpr4, label='30Sec_25Hz (AUC= %.4f)'%y_30_25Hz_score)\n",
    "ax.plot([0, 1], [0, 1], 'r--')\n",
    "ax.set_xlim([0, 1])      # X축의 범위: [xmin, xmax]\n",
    "ax.set_ylim([0, 1])     # Y축의 범위: [ymin, ymax]\n",
    "ax.set_xlabel('False positive rate')      # X축의 범위: [xmin, xmax]\n",
    "ax.set_ylabel('True positive rate')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score\n",
    "from copy import copy\n",
    "a=np.linspace(0.000,1.000,1001)\n",
    "report1=0\n",
    "tresh_hold=0.000\n",
    "for i in a:\n",
    "    t_prob=np.where(predict_30_25Hz>i,1,0)\n",
    "    report = f1_score(y_30_25Hz,t_prob)\n",
    "    if report1<=report:\n",
    "        tresh_hold=copy(i)\n",
    "        report1=copy(report)\n",
    "print(f\"Threshholds= {tresh_hold} f1-score={report1}\")\n",
    "classes = ['Non-AF','AF']\n",
    "t_prob=np.where(predict_30_25Hz>tresh_hold,1,0)\n",
    "report = classification_report(y_30_25Hz, t_prob, target_names=classes)\n",
    "cm = confusion_matrix(y_30_25Hz, t_prob)\n",
    "cm_display = ConfusionMatrixDisplay(cm,\n",
    "                              display_labels=classes).plot()\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torchmetrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from copy import copy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "device0 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "def resized(data, N):\n",
    "    M = data.size\n",
    "    res = np.empty(N, data.dtype)\n",
    "    carry = 0\n",
    "    m = 0\n",
    "    for n in range(N):\n",
    "        sum = carry\n",
    "        while m*N - n*M < M:\n",
    "            sum += data[m]\n",
    "            m += 1\n",
    "        carry = (m-(n+1)*M/N)*data[m-1]\n",
    "        sum -= carry\n",
    "        res[n] = sum*N/M\n",
    "    return res\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, label, data_list, transform=None, target_transform=None):\n",
    "        self.PPG_data = data\n",
    "        self.PPG_label = label\n",
    "        self.PPG_data_path = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.PPG_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signal_tensor = self.PPG_data[idx]\n",
    "        AF_signal_label = self.PPG_label[idx]\n",
    "        AF_data_path = self.PPG_data_path[idx]\n",
    "        return signal_tensor, AF_signal_label, AF_data_path\n",
    "# model\n",
    "\n",
    "\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=50,\n",
    "                               kernel_size=3, padding='same', padding_mode='replicate')\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout1d(0.5)\n",
    "        self.pool1 = torch.nn.MaxPool1d(kernel_size=5)\n",
    "        self.conv2 = nn.Conv1d(in_channels=50, out_channels=50,\n",
    "                               kernel_size=3, padding='same', padding_mode='replicate')\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout1d(0.5)\n",
    "        self.pool2 = torch.nn.MaxPool1d(kernel_size=5)\n",
    "        self.fc1 = nn.Linear(1500, 200, bias=False)\n",
    "        self.fc2 = nn.Linear(200, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Data Load\n",
    "test_csv_path = '../../docker/data'\n",
    "test_data_list = glob(test_csv_path+'/**/*.csv')\n",
    "test_data = torch.empty(len(test_data_list), 1, 750)\n",
    "test_label = torch.empty(len(test_data_list), 1)\n",
    "for i in tqdm(range(len(test_data_list))):\n",
    "    signal_csv = pd.read_csv(test_data_list[i])['PPG'].to_numpy()\n",
    "    test_data_list[i].find('positive')\n",
    "    AF_signal_label = 0\n",
    "    if test_data_list[i].find('positive') != -1:\n",
    "        AF_signal_label = 1\n",
    "    else:\n",
    "        AF_signal_label = 0\n",
    "\n",
    "    test_data[i] = torch.tensor(resized(signal_csv, 750))\n",
    "    test_label[i] = torch.tensor([AF_signal_label])\n",
    "test_dataset = CustomDataset(test_data, test_label, test_data_list)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# model_load\n",
    "accuracy = torchmetrics.Accuracy(task=\"binary\", num_classes=1).to(device0)\n",
    "model = CNN1D().to(device0)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load(\n",
    "    '../../model/Waveform/Type_normalization/CNN_1D.pt'))\n",
    "\n",
    "# Predict\n",
    "m = nn.Sigmoid()\n",
    "y_30_25Hz = torch.empty((0, 1))\n",
    "predict_30_25Hz = torch.empty((0, 1))\n",
    "file_list = []\n",
    "with torch.no_grad():\n",
    "    for x, y, path in test_dataloader:\n",
    "        y = y.to(device0).float()\n",
    "        x = x.to(device0).float()\n",
    "        y_30_25Hz = torch.cat([y_30_25Hz, y.cpu()])\n",
    "        predict = model(x).to(device0)\n",
    "        predict_30_25Hz = torch.cat([predict_30_25Hz, m(predict).cpu()])\n",
    "        acc = accuracy(predict, y)\n",
    "        cost = criterion(predict, y)\n",
    "        file_list.append(path[0])\n",
    "y_30_25Hz_score = roc_auc_score(y_30_25Hz, predict_30_25Hz)\n",
    "print(f'30Sec_25Hz (AUC={y_30_25Hz_score :.4f})')\n",
    "\n",
    "a = np.linspace(0.000, 1.000, 1001)\n",
    "report1 = 0\n",
    "tresh_hold = 0.000\n",
    "for i in a:\n",
    "    t_prob = np.where(predict_30_25Hz > i, 1, 0)\n",
    "    report = f1_score(y_30_25Hz, t_prob)\n",
    "    if report1 <= report:\n",
    "        tresh_hold = copy(i)\n",
    "        report1 = copy(report)\n",
    "classes = ['Non-AF', 'AF']\n",
    "t_prob = np.where(predict_30_25Hz > tresh_hold, 1, 0)\n",
    "report = classification_report(y_30_25Hz, t_prob, target_names=classes)\n",
    "pd.DataFrame({'FilePath': file_list, 'AF_GT': np.array(y_30_25Hz)[:,0],\n",
    "             'AF_pred': t_prob[:,0]}).to_csv('../../docker/data/predict.csv',index=False)\n",
    "print(f\"Threshholds= {tresh_hold} f1-score={report1}\")\n",
    "print(report)\n",
    "cm = confusion_matrix(y_30_25Hz, t_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'FilePath': file_list, 'AF_GT': np.array(y_30_25Hz)[:,0],\n",
    "             'AF_pred': t_prob[:,0]}).to_csv('../../docker/data/predict.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
